% !TEX root = ../main.tex

\chapter{绪论}

\section{研究背景与意义}

全球卫星导航系统（Global Navigation Satellite System, GNSS）是由卫星星座向全球用户提供定位、导航和授时服务的空间系统。典型的GNSS包括美国的GPS、俄罗斯的GLONASS、欧洲的Galileo和中国的北斗卫星导航系统（BDS）等，它们通过卫星发射无线电导航信号，供用户接收机实时解算位置信息。在军用和民用领域，GNSS已成为时空信息获取的基础支撑，其功能涵盖从日常车辆导航、智能手机定位到航空航海、高精度测绘和授时同步等各个方面。GNSS为全球经济发展和国家安全提供了关键支撑，被誉为现代社会的“时空基准”。

自20世纪70年代GPS首先部署以来，全球导航卫星系统得到了长足发展。GPS系统不断现代化，卫星更新换代并增加新信号频率，提高了服务精度和抗干扰能力；同时引入了如弹性功率（Flex Power）等新技术以增强军事信号的性能。俄罗斯的GLONASS完成恢复并实现全天候全球服务；欧盟的Galileo系统于2019年底初步建成，提供全球服务。中国的北斗系统分三期建设，其中北斗三号于2020年完成全球组网，采用了星间链路、新一代铷原子钟和被动氢原子钟等先进技术，显著提升了导航信号性能，其10天频率稳定度达到$10^{–15}$量级，性能指标已经与GPS相当。北斗系统创新融合了导航与通信能力，具备定位导航授时、星基增强、地基增强、精密单点定位、短报文通信和国际搜救等多种服务能力。作为北斗三号系统特色服务之一，其播发B2b信号，向用户播发卫星轨道改正数、钟差改正数和码偏差等信息，可向中国及周边地区提供实时的精密单点定位（Precise Point Positioning，PPP）服务。


随着 GNSS 技术的发展，高精度定位方法逐步由依赖局部参考站的相对定位，向基于精密产品的绝对定位演进。实时动态差分定位（Real-time Kinematic，RTK）是较早实现工程化厘米级定位精度的技术之一。该方法通过引入局域参考站，对流动站与参考站的观测值进行双差处理，有效消除了接收机与卫星钟差，并显著削弱轨道误差、对流层延迟及电离层延迟等空间相关误差，从而实现整周模糊度的快速固定，获得高精度定位结果。然而，RTK 的高精度建立在误差高度相关的基础之上，其定位性能随基线长度增加而明显下降，通常要求流动站与参考站之间的距离不超过 20 km。在大范围应用场景下，需要建设高密度参考站网络，不仅建设与维护成本高，而且依赖双向通信链路，系统扩展性受限，同时改正数播发需获取用户位置信息，难以充分保障用户隐私性。

为突破对参考站和基线长度的依赖，精密单点定位（Precise Point Positioning，PPP）逐渐发展并得到广泛关注。PPP 采用非差观测模型，结合精密卫星轨道和钟差产品，对各类误差进行独立建模或参数估计，可在单台接收机条件下实现绝对定位。与 RTK 相比，PPP 在系统结构上更加灵活，无需建设局部参考站网络，且通常采用单向通信方式，显著降低了通信负担并增强了用户隐私保护能力。然而，由于 PPP 中整周模糊度以实数形式估计，且受卫星空间几何构型变化缓慢及参数相关性较强等因素影响，其收敛时间通常较长，往往需要数十分钟才能达到稳定解，在实时应用中定位精度多为分米级，限制了其在对快速高精度定位有较高需求场景中的应用。

在此基础上，PPP 模糊度固定技术（PPP Ambiguity Resolution，PPP-AR）进一步提升了精密单点定位的性能。PPP-AR 通过引入卫星端偏差产品和硬件延迟改正信息，恢复非差整周模糊度的整数特性，实现模糊度的可靠固定。该方法在保持 PPP 全球覆盖能力和单站作业优势的同时，显著缩短了定位收敛时间，并将定位精度提升至厘米级，使其在实时高精度定位应用中具备与 RTK 相当的性能表现，成为当前高精度 GNSS 定位技术的重要发展方向。

在 RTK 定位中，由于采用双差观测模型，卫星和接收机端的大部分码偏差可被有效消除，DCB 对定位结果的影响相对较弱，通常不需要显式建模。然而，在 PPP 及 PPP-AR 中，非差观测模型使得码偏差无法通过差分消除，DCB 将直接影响伪距观测一致性、电离层延迟参数估计以及多频、多系统观测的融合精度。特别是在 PPP-AR 应用中，DCB 的精度与稳定性直接关系到模糊度固定的成功率和可靠性：不准确的 DCB 改正会引入系统性偏差，导致电离层参数估计失真，从而延缓收敛过程，甚至引发模糊度错误固定。因此，高质量的 DCB 产品是保障 PPP 与 PPP-AR 高精度、高可靠定位性能的重要基础。

高精度定位依赖GNSS观测量的稳定性和误差可预测性，各种细微的信号异常都可能对解算精度造成影响。近年来，为了提升抗干扰能力，GPS引入了弹性功率功能，即卫星可在不同导航信号之间动态重新分配发射功率。弹性功率常在军事行动中启用，用于增强军码信号功率、提高抗干扰性能，但这一过程对民用信号不公开透明。研究表明，弹性功率的启用会导致卫星信号特性发生细微变化，例如引起差分码偏差（DCB）变化、载波相位漂移以及多址干扰等。这些变化将破坏原有误差校正模型的稳定性，给PPP等高精度解算引入额外误差源。如果用户无法及时察觉并改正，定位精度将受到明显影响。因此，随着高精度定位对信号品质要求的提高，研究GNSS卫星的新功能（如弹性功率）对定位性能的影响，具有重要意义。

GNSS异常事件是指影响卫星导航系统正常服务性能的非正常现象或事件。按来源可分为卫星系统自身异常和外部环境/人为干扰事件。卫星系统自身异常包括卫星星载设备故障（如原子钟故障、卫星姿态失控、电源异常等）、卫星轨道/星历异常（轨道机动或星历数据错误）以及信号异常（信号质量畸变、信号功率异常变化等）。外部环境因素则包括电离层异常（太阳风暴引起电离层扰动导致信号延迟异常）、电磁干扰和欺骗（如恶意干扰器或欺骗信号导致接收机定位出错）等。例如2025年12月，在中国南京局部地区就发生了GNSS信号受强干扰压制的事件，导致该区域GPS和北斗民用频段导航服务集体失灵，大批导航设备出现“定位漂移”或无解算结果的异常现象。再如2019年7月Galileo系统曾因地面控制设施故障导致全球服务中断一周，这些都属于GNSS异常事件的典型案例。概括而言，GNSS异常事件类型多样，既有源自系统内部的卫星故障，也有外部环境和人为因素造成的干扰。本文所关注的“弹性功率事件”和“星载产品异常”则分别属于信号异常和卫星设备异常的特定类型。

GNSS异常事件可能对定位授时服务以及相关应用产生严重影响。一方面，在定位精度上，异常事件会降低导航解算的准确性。例如卫星原子钟发生跳变将直接引入数米甚至数十米的定位误差，信号弹性功率调整引起的偏差变化也会破坏精密定位求解的误差模型，导致解算精度下降。另一方面，在可靠性和可用性上，异常事件可能导致导航服务中断或可用卫星数量减少。当异常影响大范围用户时，可能带来经济损失和安全隐患。据研究估计，如果GPS服务整体中断，美国经济每日将损失高达约10亿美元。近期南京局部发生的导航瘫痪也造成外卖、网约车等基于定位服务的行业短暂混乱。在军事领域，GNSS异常更可能被对手利用以削弱武器制导。例如乌克兰战场的实战经验表明，先进的电子战技术能够有效干扰削弱GPS制导武器的作战效能。因此，GNSS异常事件不仅关系到定位精度和民用应用的正常运作，更关乎国家关键基础设施和国防安全。提高对异常事件的防范和应对能力已成为保障GNSS服务连续性和可靠性的迫切要求。

面对GNSS异常事件可能造成的危害，及时检测和识别这些事件是保证导航服务可靠性的关键。GNSS异常事件的检测包括对空间 segment（卫星端）和用户段的监测两方面：在空间段，GNSS系统运行管理部门（如GPS控控站、北斗地面运控系统等）会实时监控卫星状态，一旦发现卫星发生故障（比如星历异常或原子钟超限漂移），会通过导航电文将卫星标记为“不健康”以提醒用户。在用户段和学术研究方面，国际GNSS服务组织（IGS）以及中国的国际GNSS监测评估系统（iGMAS）建立了全球监测站网，采集各系统卫星的信号数据，以事后分析和实时质量控制相结合的方式检测异常。例如，针对GPS的弹性功率事件，研究人员利用IGS/iGMAS跟踪站数据和高增益天线观测，分析各频段信号载噪比变化，成功辨识出卫星何时开启了功率重分配。又如在电离层异常监测上，有专门的电离层监测站网通过观测GNSS信号延迟来探测空间天气对导航的影响。除了基于全球站网的数据分析，接收机自主完好性监测（RAIM）算法也广泛应用于用户终端，用以自主检测和隔离故障卫星。总体而言，GNSS异常事件的检测技术涵盖了从地基监测网络到用户端算法的多层次手段。但仍有一些异常（例如卫星弹性功率的启停、星载设备细微异常等）缺乏公开的事先通知，需要依靠用户自行探测和事后分析加以识别。这就要求发展更加灵敏和智能的异常检测方法，以提升GNSS在复杂环境下的服务完好性。


\section{研究现状与存在问题}

\subsection{弹性功率事件特性的研究}

弹性功率（Flex Power）作为GPS等卫星新增的一种功率控制功能，引起了诸多学者的关注。在原理上，弹性功率通过可编程的载荷调整，将卫星发射总功率在不同信号分量之间重新分配，以增强特定信号（通常为军用P(Y)码或M码）的功率。例如，文献报道GPS Block IIR-M和IIF型卫星在开启弹性功率时，L1和L2频段的P(Y)码信号功率可比正常水平提高约6 dB和5 dB，而民用C/A码等信号功率保持不变，总发射功率也不增加。这表明弹性功率主要通过削减其他分量（如未使用的M码或其他频率）的功率来强化授权信号。有关弹性功率事件发生特性的研究还包括其开启的模式和频次。有研究统计了2020年前后GPS卫星多次弹性功率的启停时间，发现其多发生于特定军事演习或冲突期间，并呈现出按需开启、区域覆盖的特点。例如，同济大学GNSS团队的分析将2020年发生的弹性功率按星下点轨迹范围和增强功率幅度分为了6种模式，并指出某些模式下功率增强覆盖区域固定于特定地理中心。2023年的实时监测还发现了一种新的弹性功率模式，覆盖范围更广并出现多个地理中心。这些工作揭示了弹性功率事件在时空上的分布特征，为后续解读其影响提供了基础。然而，目前公开资料中针对弹性功率事件的细节仍有限。由于此功能涉及军事应用，官方很少发布其启停信息，现有研究多数依赖事后观测数据进行倒推分析。对于弹性功率事件可能引发的信号质量变化，比如对差分码偏差（DCB）的影响，一些初步研究已经有所发现。但仍需要更深入的数据分析来全面掌握弹性功率事件的特性，例如不同卫星之间差异、持续时间分布以及对各类信号指标（载噪比、相位、测距精度等）的定量影响等。存在的问题在于，目前对弹性功率的认知主要停留在定性描述和单次事件分析上，对其规律性的统计研究不足。这限制了进一步评估弹性功率对GNSS系统性能的整体影响。

研究表明，GPS卫星在激活Flex Power期间，其群延迟变化（DCB）可达0.4 ns（约12 cm） 。对于分米级甚至厘米级的定位服务，这种量级的偏差若未被实时检测与修正，将直接破坏模糊度的整数约束条件，导致定位结果出现数米级的漂移，这对自动驾驶车辆的车道级定位是致命的 。在高精度处理中，DCB通常与电离层总电子含量（TEC）参数强耦合。未被分离的卫星端Flex Power偏差常被误判为电离层异常，进而污染广域电离层模型，影响区域内所有单频用户的定位精度 。不同于GPS卫星亚纳秒级（<1 ns）的DCB变化，BDS-2卫星（主要为GEO和IGSO轨道）在进行功率调整时，观测到的DCB变化幅度巨大，可达9至14纳秒（约3-4米）8。这种剧烈的跳变对任何依赖码观测量的定位解算（如SPP、MW组合）都是毁灭性的。此外，由于BDS-2 GEO卫星相对于地面测站静止，其多路径效应呈现恒定特征，这使得利用$C/N_0$变化来区分功率调整与环境多径变得更加困难。

\subsection{弹性功率事件的检测方法研究}

由于弹性功率事件不会在导航电文中直接通告，用户需自主检测卫星是否开启了弹性功率以满足高精度定位需求。针对这一需求，国内外学者提出了多种检测方法。一类方法是高增益天线监测法，它利用大口径（如30米级）高增益天线直接观测卫星下行信号的频谱特性，能够分离出各信号分量的功率谱密度，检测性能高。德国宇航中心（DLR）利用Weilheim地面站进行了大量此类实验。但该方法设备昂贵，无法实现全球实时覆盖。更为主流的方法是基于IGS网络载噪比（$C/N_0$）监测法。由于弹性功率是卫星端的行为，其引起的信号强度变化应被可视范围内的所有地面接收机共同观测到。通过对全球分布的IGS测站数据进行加权平均或聚类分析，可以有效识别出卫星端的功率跳变，并剔除测站端的本地多路径干扰。在此方法上，还有研究利用了机器学习针对海量监测数据的处理，近年来涌现出基于监督学习的检测模型。例如，利用XGBoost或随机森林（Random Forest）算法，以卫星高度角、方位角、轨道位置及历史$C/N_0$作为特征输入，训练分类器以识别弹性功率的激活状态。研究表明，此类方法在低轨卫星（LEO）接收机数据上的检测准确率可超过99\%。

尽管弹性功率的检测研究已取得进展，但仍存在诸多局限。Esenbuğa等人提出的FPD虽然实现了自动化检测阶跃变化，但存在检测速度慢，且必须使用足够多的测站来进行联合判断以得到鲁棒的检测结果。国防科技大学提出的基于随机森林的检测方法可以实现实时监测，实现了动态阈值功能，但需要数据进行多项式拟合，准确率不代表其泛化性，同时仍然需要足够多人工标注的数据用于监督学习。同济大学提出的基于载噪比时空建模的方法检测速度虽然快，但对每个接收机需要大量数据进行建模，更换接收机和天线后则需要需重新建模。综上所述，需要一种数据需求量更少、普适性更高、准确率更高的检测方法来满足弹性功率的检测需求。

\subsection{弹性功率对定位影响的研究}


\subsection{GNSS星载产品异常特性研究}

GNSS星载产品主要指卫星上搭载的关键载荷，如原子钟、信号发生器、天线等。其中原子钟作为GNSS卫星的时间基准，其性能优劣直接决定导航信号的精度和稳定性。利用多维遥测数据进行原子钟异常检测，是深入挖掘卫星“亚健康”状态的前沿方向。目前GNSS主流搭载的原子钟主要包括铷原子频标（RAFS）和被动型氢原子钟（PHM）。

铷原子频标（RAFS）广泛应用于GPS、BDS及Galileo。其工作原理基于铷原子的光抽运效应。关键的物理参量包括灯电压（Lamp Voltage）、泡温（Cell Temperature）、微波功率及激光电流（针对光抽运铷钟）。研究表明，泡温的微小波动（mK级）即可通过缓冲气体碰撞频移效应引起输出频率的漂移；而灯电压的异常下降往往是铷灯老化或充气不足的前兆 。

被动型氢原子钟（PHM）BDS-3及Galileo的主钟。其核心在于微波谐振腔的调谐。关键遥测参量包括腔温、氢气压力、离子泵电流及变容二极管电压。变容二极管电压直接反映了自动调谐回路（ACT）对腔体频率的锁定状态，其异常波动通常预示着热控系统失效或微波腔体的物理形变 。

但星载原子钟在长期运行中不可避免地受到空间环境和元器件老化等因素影响，会出现各种异常现象。常见的星载钟异常包括：频率快变（频率输出在短时间内突跳）、频率慢变（频率产生持续偏移漂移）以及瞬时的信号毛刺等。这些异常会直接反映在卫星钟差数据中，例如钟差序列出现陡峭的跃变、漂移趋势改变或孤立的离群点等。据统计，各GNSS系统的星载钟在轨运行均出现过异常事件。例如，GLONASS某些卫星在个别月份曾出现日频率稳定度显著变差，钟差中存在较大异常值，被推测与星载钟调整频率/相位有关。再如Galileo系统在2016-2017年期间有多颗铷钟和氢钟失效，需要启用冗余钟，导致卫星服务暂时中断。而在北斗系统中，BDS-2卫星早期铷钟曾暴露出漂移率偏大的问题，相比GPS卫星铷钟准确度和稳定度存在一定差距；不过BDS-3改进了钟组配置，采用铷钟+氢钟组合，使性能指标大幅提升，氢钟日稳定度达到E-15量级，与GPS最新铷钟相当。这表明通过技术升级可以降低钟差长期漂移等慢变异常的幅度。然而即便总体性能提升，星载钟偶发异常仍难以完全避免。

\subsection{GNSS星载产品异常检测研究}

传统的原子钟异常检测主要基于地面监测站解算得到的精密钟差（Clock Bias）或钟速（Clock Drift）序列。常用的方法包括中位数绝对偏差（MAD）法、贝叶斯假设检验和动态阿伦方差（DAVAR）检测法。MAD用于检测钟差序列中的离群值实现检测。贝叶斯假设检验用于识别频率跳变，DAVAR则分析频率稳定度的时变特征以实现检测。

然而，这些方法本质上是基于结果的检测，因此天然带有滞后性特征，即只有当原子钟物理性能恶化到足以引起输出信号显著偏差时，才能被检测到。此时，异常可能已经影响了用户的定位服务。另一特征是误差耦合，即地面解算的钟差包含轨道误差、对流层延迟及测量噪声。微小的原子钟异常（如$10^{-14}$量级的频率漂移）往往被这些背景噪声淹没，难以分离。

为了克服传统方法的局限，利用卫星下行的工程遥测数据进行“基于原因”的检测成为研究新趋势。遥测数据具有高维、非线性及强耦合特征，诸多基于数据驱动采用机器学习的算法被广泛提出。有研究利用长短期记忆网络（LSTM）学习原子钟在健康状态下各遥测参量（如温度、电压、电流）之间的时序相关性。当异常发生时（例如温度正常但频率控制电压突变），重构误差（Reconstruction Error）会显著增大，从而实现异常报警。该方法在检测RAFS的隐性故障方面表现优异。随机森林（Random Forest）与XGBoost通过监督学习的方法同样被应用于该领域，建立遥测参量与原子钟频率输出之间的映射模型。研究表明，在BDS-3卫星上，利用遥测数据训练的模型可以高精度预测钟差的变化趋势，辅助识别非物理性的钟差跳变。

\section{本文研究内容}



\section{本文组织架构}
